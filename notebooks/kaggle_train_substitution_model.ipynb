{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ… LEMMA IMO Substitution Model Training\n",
                "\n",
                "This notebook trains a DistilBERT model to predict useful substitutions for IMO problems.\n",
                "\n",
                "**GPU Quota**: 30 hours/week (P100)\n",
                "**Estimated Training Time**: 1-2 hours\n",
                "\n",
                "## Setup\n",
                "1. Enable GPU: Settings â†’ Accelerator â†’ GPU P100\n",
                "2. Run all cells\n",
                "3. Download the ONNX model at the end"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install transformers datasets scikit-learn onnx onnxruntime -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import torch\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from typing import List, Dict\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import (\n",
                "    DistilBertTokenizer,\n",
                "    DistilBertForSequenceClassification,\n",
                "    Trainer,\n",
                "    TrainingArguments,\n",
                ")\n",
                "from sklearn.preprocessing import MultiLabelBinarizer\n",
                "\n",
                "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Substitution Vocabulary\n",
                "\n",
                "These are the substitutions the model will learn to predict."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Substitution vocabulary - what the model will predict\n",
                "SUBSTITUTION_VOCAB = [\n",
                "    \"x = 0\",\n",
                "    \"y = 0\",\n",
                "    \"x = y\",\n",
                "    \"x = 1\",\n",
                "    \"y = 1\",\n",
                "    \"a = b = c = 1\",\n",
                "    \"abc = 1 constraint\",\n",
                "    \"Apply AM-GM\",\n",
                "    \"Apply Cauchy-Schwarz\",\n",
                "    \"Assume f is linear\",\n",
                "    \"Assume f is injective\",\n",
                "    \"Assume f is monotonic\",\n",
                "    \"Check small cases\",\n",
                "    \"Use modular arithmetic\",\n",
                "    \"Homogenize\",\n",
                "    \"WLOG assume ordering\",\n",
                "    \"Substitute c = 1/(ab)\",\n",
                "    \"y = f(x)\",\n",
                "    \"x = -y\",\n",
                "    \"Consider p = 2 separately\",\n",
                "]\n",
                "\n",
                "print(f\"Vocabulary size: {len(SUBSTITUTION_VOCAB)} substitutions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Training Data\n",
                "\n",
                "Annotated IMO problems with substitutions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training data - annotated IMO problems\n",
                "TRAINING_DATA = [\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„âº â†’ â„âº such that for every x âˆˆ â„âº, there is exactly one y âˆˆ â„âº satisfying xf(y) + yf(x) â‰¤ 2.\",\n",
                "        \"substitutions\": [\"x = y\", \"x = 1\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„¤ â†’ â„¤ such that for all integers a, b: f(2a) + 2f(b) = f(f(a + b)).\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"x = y\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„ â†’ â„ such that f(f(x)f(y)) + f(x + y) = f(xy) for all x, y âˆˆ â„.\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"x = 1\", \"y = 1\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„ â†’ â„ that satisfy f(x + f(x + y)) + f(xy) = x + f(x + y) + yf(x).\",\n",
                "        \"substitutions\": [\"y = 0\", \"x = 0\", \"Assume f is linear\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„ â†’ â„ such that for all x, y âˆˆ â„: f(âŒŠxâŒ‹y) = f(x)âŒŠf(y)âŒ‹.\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"x = 1\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Prove that for positive reals a, b, c with abc = 1: (a-1+1/b)(b-1+1/c)(c-1+1/a) â‰¤ 1.\",\n",
                "        \"substitutions\": [\"abc = 1 constraint\", \"a = b = c = 1\", \"Apply AM-GM\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Prove that for positive reals a, b, c: a/âˆš(aÂ² + 8bc) + b/âˆš(bÂ² + 8ca) + c/âˆš(cÂ² + 8ab) â‰¥ 1.\",\n",
                "        \"substitutions\": [\"a = b = c = 1\", \"Apply Cauchy-Schwarz\", \"Homogenize\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all positive integers n for which n divides 2^n + 1.\",\n",
                "        \"substitutions\": [\"Check small cases\", \"Use modular arithmetic\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all pairs (a,b) of positive integers such that gcd(a^n + b, b^n + a) is eventually constant.\",\n",
                "        \"substitutions\": [\"Check small cases\", \"Use modular arithmetic\", \"Consider p = 2 separately\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„• â†’ â„• such that f(m + f(n)) = f(f(m)) + f(n) for all m, n.\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"y = f(x)\", \"Assume f is injective\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Let a, b, c be positive reals with a + b + c = 3. Prove that aÂ² + bÂ² + cÂ² â‰¥ 3.\",\n",
                "        \"substitutions\": [\"Apply Cauchy-Schwarz\", \"a = b = c = 1\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„š â†’ â„š such that f(x + f(y)) = f(x) + y for all x, y âˆˆ â„š.\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"Assume f is linear\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Let a, b, c be positive reals with abc = 1. Prove that 1/(aÂ³(b+c)) + 1/(bÂ³(c+a)) + 1/(cÂ³(a+b)) â‰¥ 3/2.\",\n",
                "        \"substitutions\": [\"abc = 1 constraint\", \"a = b = c = 1\", \"Apply AM-GM\", \"WLOG assume ordering\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Find all functions f: â„ â†’ â„ such that f(xÂ²) - f(yÂ²) = (f(x) + y)(x - f(y)).\",\n",
                "        \"substitutions\": [\"x = 0\", \"y = 0\", \"x = y\", \"x = -y\"]\n",
                "    },\n",
                "    {\n",
                "        \"problem_text\": \"Prove that for all positive integers n, the number n^(n+1) + (n+1)^n is divisible by gcd(n, n+1) + 1.\",\n",
                "        \"substitutions\": [\"Check small cases\", \"Use modular arithmetic\"]\n",
                "    },\n",
                "]\n",
                "\n",
                "print(f\"Training examples: {len(TRAINING_DATA)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SubstitutionDataset(Dataset):\n",
                "    def __init__(self, problems, tokenizer, mlb, max_length=256):\n",
                "        self.tokenizer = tokenizer\n",
                "        self.mlb = mlb\n",
                "        self.max_length = max_length\n",
                "        self.data = problems\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        item = self.data[idx]\n",
                "        \n",
                "        # Tokenize\n",
                "        encoding = self.tokenizer(\n",
                "            item['problem_text'],\n",
                "            truncation=True,\n",
                "            max_length=self.max_length,\n",
                "            padding='max_length',\n",
                "            return_tensors='pt',\n",
                "        )\n",
                "        \n",
                "        # Multi-label target\n",
                "        labels = self.mlb.transform([item['substitutions']])\n",
                "        \n",
                "        return {\n",
                "            'input_ids': encoding['input_ids'].squeeze(),\n",
                "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
                "            'labels': torch.tensor(labels.squeeze(), dtype=torch.float),\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize Model & Tokenizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize\n",
                "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
                "mlb = MultiLabelBinarizer(classes=SUBSTITUTION_VOCAB)\n",
                "mlb.fit([SUBSTITUTION_VOCAB])\n",
                "\n",
                "# Create dataset\n",
                "dataset = SubstitutionDataset(TRAINING_DATA, tokenizer, mlb)\n",
                "\n",
                "# Split into train/val (80/20)\n",
                "train_size = int(0.8 * len(dataset))\n",
                "train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
                "val_dataset = torch.utils.data.Subset(dataset, range(train_size, len(dataset)))\n",
                "\n",
                "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model\n",
                "model = DistilBertForSequenceClassification.from_pretrained(\n",
                "    'distilbert-base-uncased',\n",
                "    num_labels=len(SUBSTITUTION_VOCAB),\n",
                "    problem_type='multi_label_classification',\n",
                ")\n",
                "\n",
                "print(f\"Model loaded with {len(SUBSTITUTION_VOCAB)} output labels\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(pred):\n",
                "    labels = pred.label_ids\n",
                "    preds = (torch.sigmoid(torch.tensor(pred.predictions)) > 0.5).numpy()\n",
                "    \n",
                "    # Per-sample exact match\n",
                "    exact_match = np.all(preds == labels, axis=1).mean()\n",
                "    \n",
                "    # Per-label accuracy\n",
                "    label_accuracy = (preds == labels).mean()\n",
                "    \n",
                "    return {\n",
                "        'exact_match': exact_match,\n",
                "        'label_accuracy': label_accuracy,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./results',\n",
                "    num_train_epochs=20,\n",
                "    per_device_train_batch_size=4,\n",
                "    per_device_eval_batch_size=4,\n",
                "    warmup_steps=50,\n",
                "    weight_decay=0.01,\n",
                "    logging_dir='./logs',\n",
                "    logging_steps=10,\n",
                "    evaluation_strategy='epoch',\n",
                "    save_strategy='epoch',\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model='label_accuracy',\n",
                "    greater_is_better=True,\n",
                "    fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
                ")\n",
                "\n",
                "# Trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=val_dataset,\n",
                "    compute_metrics=compute_metrics,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train!\n",
                "print(\"Starting training...\")\n",
                "trainer.train()\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_substitutions(text, top_k=3):\n",
                "    \"\"\"Predict substitutions for a problem.\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    inputs = tokenizer(\n",
                "        text, \n",
                "        return_tensors='pt', \n",
                "        max_length=256, \n",
                "        truncation=True, \n",
                "        padding='max_length'\n",
                "    )\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
                "        model.cuda()\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "    \n",
                "    probs = torch.sigmoid(outputs.logits).squeeze().cpu().numpy()\n",
                "    \n",
                "    # Get top-k\n",
                "    top_indices = probs.argsort()[-top_k:][::-1]\n",
                "    results = [(SUBSTITUTION_VOCAB[i], float(probs[i])) for i in top_indices]\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on IMO 2022 P3\n",
                "test_problem = \"Find all functions f: â„âº â†’ â„âº such that for every x âˆˆ â„âº, there is exactly one y âˆˆ â„âº satisfying xf(y) + yf(x) â‰¤ 2.\"\n",
                "\n",
                "print(\"Problem:\", test_problem[:100] + \"...\")\n",
                "print(\"\\nPredicted substitutions:\")\n",
                "for sub, prob in predict_substitutions(test_problem, top_k=5):\n",
                "    print(f\"  {prob:.2%} - {sub}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on an algebra problem\n",
                "test_algebra = \"Let a, b, c be positive reals with abc = 1. Prove that a + b + c >= 3.\"\n",
                "\n",
                "print(\"Problem:\", test_algebra)\n",
                "print(\"\\nPredicted substitutions:\")\n",
                "for sub, prob in predict_substitutions(test_algebra, top_k=5):\n",
                "    print(f\"  {prob:.2%} - {sub}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Export to ONNX"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save PyTorch model first\n",
                "model_dir = Path('./final_model')\n",
                "model_dir.mkdir(exist_ok=True)\n",
                "\n",
                "trainer.save_model(str(model_dir))\n",
                "tokenizer.save_pretrained(str(model_dir))\n",
                "\n",
                "# Save vocab\n",
                "with open(model_dir / 'label_vocab.json', 'w') as f:\n",
                "    json.dump(SUBSTITUTION_VOCAB, f)\n",
                "\n",
                "print(f\"Model saved to {model_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX\n",
                "model.eval()\n",
                "model.cpu()\n",
                "\n",
                "# Dummy input\n",
                "dummy_input = tokenizer(\n",
                "    \"Find all functions f such that f(x+y) = f(x) + f(y)\",\n",
                "    return_tensors='pt',\n",
                "    max_length=256,\n",
                "    truncation=True,\n",
                "    padding='max_length'\n",
                ")\n",
                "\n",
                "onnx_path = model_dir / 'substitution_model.onnx'\n",
                "\n",
                "torch.onnx.export(\n",
                "    model,\n",
                "    (dummy_input['input_ids'], dummy_input['attention_mask']),\n",
                "    str(onnx_path),\n",
                "    input_names=['input_ids', 'attention_mask'],\n",
                "    output_names=['logits'],\n",
                "    dynamic_axes={\n",
                "        'input_ids': {0: 'batch'},\n",
                "        'attention_mask': {0: 'batch'},\n",
                "        'logits': {0: 'batch'},\n",
                "    },\n",
                "    opset_version=14,\n",
                ")\n",
                "\n",
                "print(f\"ONNX model saved to {onnx_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify ONNX model\n",
                "import onnxruntime as ort\n",
                "\n",
                "session = ort.InferenceSession(str(onnx_path))\n",
                "result = session.run(\n",
                "    None,\n",
                "    {\n",
                "        'input_ids': dummy_input['input_ids'].numpy(),\n",
                "        'attention_mask': dummy_input['attention_mask'].numpy(),\n",
                "    }\n",
                ")\n",
                "\n",
                "print(f\"âœ… ONNX verification passed! Output shape: {result[0].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Download Model\n",
                "\n",
                "Download these files for LEMMA integration:\n",
                "- `final_model/substitution_model.onnx` - For Rust inference\n",
                "- `final_model/label_vocab.json` - Substitution vocabulary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create zip for easy download\n",
                "import shutil\n",
                "\n",
                "shutil.make_archive('lemma_substitution_model', 'zip', model_dir)\n",
                "print(\"Created: lemma_substitution_model.zip\")\n",
                "print(\"\\nDownload this file and extract to: c:\\\\rust\\\\math-monster\\\\model\\\\\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List files for download\n",
                "print(\"Files to download:\")\n",
                "for f in model_dir.iterdir():\n",
                "    size_kb = f.stat().st_size / 1024\n",
                "    print(f\"  {f.name}: {size_kb:.1f} KB\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}